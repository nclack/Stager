{"name":"Stager","tagline":"Image Registration and Analysis Interface","body":"## Image Registration and Analysis Interface ‘Stager’\r\n\r\n###ROI Selection \r\n\r\nAllow the user to select an algorithm for ROI mask/map creation OR use a pre-computed ROI mask/map. In the future, support field-of-view search feature i.e. if the user selects a recorded volume, move scanner to find optimal alignment between pre-recorded volume and live acquisition.\r\n\r\n###Image Registration\r\n\r\nGiven a reference volume perform allow user to choose a image registration algorithm (2D FFT cross correlation) and save the registered data either in the standard tiff format OR in a flat binary format (uint16) - one volume per file, one trials worth of files per directory with a standard naming of the files and directories. Add functionality to set the locations of these files to be on the cluster. In the future, other ways of sending the data to the network should be explored too. Performance Requirement: 8 Hz for 4 planes, 30 Hz for 1 plane.\r\n\r\nFuture work: Possibly allow user to specify or add registration algorithms. \r\n\r\n###ROI/Map\r\n\r\nROIs can be given in two forms, either a binary ROI mask or a weighted Map. Given a set of ROIs (either binary or weighted) compute the inner product of each ROI with the current frame (either with or without motion registration). Performance Requirement: (8 Hz for 4 planes, 30 Hz for 1 plane)\r\n\r\n###Time-series display\r\n\r\nFollowing the inner product with the ROI, plot the time series. The GUI should allow users to specify which ROIs to plot. User should also be able to specify threshold for each ROI and trigger and event if an event is detected. \r\n\r\n###Analog Output/Digital Output\r\n\r\nThe time series data should be scaled and output on AO channels from one of the NI boards (scaled ±10V or 0-5V). The user should be able so specify which ROIs to send to the Analog output. In addition, they should allow the setting of thresholds to do simple event detection and output pulses on DIO lines for detected events.\r\n\r\n***\r\n\r\nComments:\r\n\r\nNS: For each ROI might want to be able to set F0 value too and then toggle between looking at F and (F-F0)/F0. Thresholds and events will probably want to be defined in the (F-F0)/F0 domain.\r\n\r\nIt would be useful to flesh out in more detail exactly what the GUI will look like in the first instance (and how you might then want to expand it in the future). For example, how will you display or not display the static reference images, ROI mask / values. How will the user be able to set which ROIs to look at live and which ROIs to send to the AO, how will thresholds be set, how will F0 be set if we want to do an (F-F0)/F0 conversion.\r\n\r\nIt would also be useful to start laying out how you plan to do this under the hood – i.e. will this run in a separate matlab, what will happen if the registration takes too long (will it drop / skip frames, will the acquisition crash, will we be warned), what sort of timing guarantees will there be.\r\n\r\nSP: you should add a neuropil capability; this will be important in many preparations.  It also introduces some problems -- the mask itself is easy, as it is an annulus that is between a range of distances away from the neuron border, but you have to exclude i) other selected ROIs and ii) pixels that are cells/big dendrites but are not part of an ROI.  ii) is tricky -- the way it is done now is that an image with peak correlation for each pixel to its 8 neighbors is computed, and any pixel where this exceeds (e.g.) 0.2 is excluded.  This is predicated on some activity being sampled, and its unclear how much activity is needed to establish this.  Its also quite processing intensive, and goes to Nick’s point about buffering data...\r\n\r\n____________________________________________________________________\r\n\r\nProgress (02/20/2015) - AM\r\n\r\nSo far it's all command line based. I've named the analysis platform \"Stager\" - for now. Here is a summary of what I've implemented so far:\r\n\r\nArchitecture:\r\n\r\nStager is based on a client/server architecture. Stager has a server which listens to clients and imports frames into Stager when the client marks the frame as ready. The client class must me initialized by any MATLAB routine which wants to send frames to the Stager. Stager itself is based on a object-oriented design - I believe this will allow for a lot of flexibility later with things like unit testing and modularity. Each instance of Stager supports arrays of time series objects and each time series object has an array of frame objects:\r\n\r\nStager (has)-> n*timeSeriesObject Arrays\r\ntimeSeriesObject (has)-> frameObject Array\r\n \r\nA timeSeriesObject can be defined for a z-Plane and channel value-pair or any other arbitrary indexing scheme. Stager currently has a routine that invokes SI5 to acquire n-Frames or uses a pre-acquired tif stack to generate a template image using Nick's pyramid scheme. As a new frame comes in, it is processed and added to the correct frameObject array within the appropriate timeSeriesObject by the Stager. The processing step currently includes the 2DFFT (x-correlation) registration. This takes~23ms+/-2ms - Note: this is on my windows virtual machine on a mac, I would expect the numbers to be much better on any SI rig machine based on FFT benchmarks I performed. Here is a rough sketch of the current scheme:\r\n\r\n\r\n\r\nImplementation Details\r\n\r\nThe stager runs in its own process i.e. scanImage and the analysis run as two separate processes (two different matlab sessions) - this allows for much better performance and avoids dropped frames on the SI5 process. Since, I have modeled the architecture as a server/client design, any service that wants to use the \"Stager\" must initialize an instance of the Stager client class. In the case of SI5, ScanImage starts a client session in a userfunction, the client maps each new incoming frame from the scanImage buffer into memory (memory mapped file) and sets a byte value - read flag. The stager server checks the flag and pulls the memory mapped frame, processes it and adds it to a timeSeries object as a frameObject. The client/server relationship between SI5 and Stager supports some low level communication, io flags, header info (channel, frameNum, zPlane) and also allows Stager to invoke some pre-defined SI functions. For example, to generate a new template image before starting acquisition, Stager can invoke the grab function in SI5 and acquire n-Frames to generate a new template image.This does not compromise The mapping of each frame and only takes ~1ms +/-3ms (again this is on my windows virtual machine on a mac). Here is a script that outlines some functionality - some of this will eventually be abstracted away in a GUI and higher level functions.\r\n\r\n\r\n\r\nNext Steps\r\nI am now working on the Mask class which allows for a \"weighted\" mask to be applied to a time series or a frame within a time series.  Next, I will work on the ability to select an ROI and plot the and output the data to AO channels and add the ability to define thresholds for DIO ouput. Once I have the basic processing pipeline complete, I will go back and add functionality like detection of hardware and then start working on a GUI.\r\n\r\n____________________________________________________________________\r\n\r\nFluoroSNNAP - UPenn\r\n\r\nDiego, thanks for sharing – no I did not know about this. Their website http://www.seas.upenn.edu/~molneuro/fluorosnnap.html has a video demo of the software and code. Also, they have a Journal of Neuroscience paper that describes their software’s capability – attached.\r\n\r\nThings I noted:\r\n\r\nIt’s designed for data that has already been acquired so it’s not designed to  be “real time” i.e. sub 30ms loop time.\r\nI do like some ideas behind the interface (ROI selection, segmentation, functional integration), which could be improved.\r\nThere are some features that we may want to include – some of the spike detection methods. However, the way I conceptualized the analysis routines was that - we should probably think of many non-essential “online” analysis methods as plugins that can be added by users.\r\nA large subset of the features (functional connectivity, phase detection, synchronization measures) i.e. Time and processor intensive algorithms are things we probably don’t want on the host computer but would want to delegate these to Spark/Thunder.\r\n\r\n____________________________________________________________________\r\n\r\nMeeting Notes with NC - 02/21/2015\r\n\r\nAO Daq - use NI DAQ board? Given 30Hz output might be overkill\r\nFor each time series data structure what happens when n->large N\r\nAllow option for FFT on downsampled image for faster registration\r\nNamed Pipes/POSIX\r\n____________________________________________________________________\r\n\r\nMeeting Notes with NS - 02/24/2015\r\n\r\nTrial info should be in the memfile header\r\nOnly keep track of last n frames\r\nExplicit error message when frame is dropped\r\nFill dropped data with NaN/Zero\r\n\r\n____________________________________________________________________\r\n\r\nMeeting Notes (Feedback) with NS - 03/31/2015\r\n\r\nDelta F/F should be user defined - plot histogram for each ROI and allow\r\nuser to pick threshold (example: 10% of values below threshold)\r\nOne template for both channels - allow user to pick the channel\r\nAllow user to input external ROI (Use codeneuro data fromat)\r\nAllow user to input external template (binary/JSON pair)\r\n\r\n____________________________________________________________________\r\n\r\n1- Save the post-registered images online to a network location (for use for instance by Thunder)\r\n2- Knobs to change contrast and colors in Stager\r\n                A. Also capability to overlay a currently acquired image and a saved one. \r\n3- Running average of x frames (to smooth and to capture sparse neurons).\r\n4- Robust and efficient calculation of F0 \r\n5- A way to select from the ROI list which ROIs go to the NI output\r\n6- A mode to downsample and reduce the refresh rate for the ROI activity display (to improve the latency)\r\n7- User function that takes ROIs dF/F, extra parameters (weight matrix, etc) and sends the output to the NI (this point I’m currently unsure if he did it or not).\r\n8 - (I don’t think it was in the specs, and I didn’t mention it today). A cross-bar to indicate the X-Y offset with respect to the reference image (very useful to center the image to previous days). And one for Z. \r\n\r\n\r\n\r\n![](https://raw.githubusercontent.com/arunesh-mittal/StagerWebpage/master/Screen%20Shot%202015-06-23%20at%208.01.52%20PM.png)\r\n\r\n```\r\n$ cd your_repo_root/repo_name\r\n$ git fetch origin\r\n$ git checkout gh-pages\r\n```\r\n\r\nIf you're using the GitHub for Mac, simply sync your repository and you'll see the new branch.\r\n\r\n### Designer Templates\r\nWe've crafted some handsome templates for you to use. Go ahead and continue to layouts to browse through them. You can easily go back to edit your page before publishing. After publishing your page, you can revisit the page generator and switch to another theme. Your Page content will be preserved if it remained markdown format.\r\n\r\n### Rather Drive Stick?\r\nIf you prefer to not use the automatic generator, push a branch named `gh-pages` to your repository to create a page manually. In addition to supporting regular HTML content, GitHub Pages support Jekyll, a simple, blog aware static site generator written by our own Tom Preston-Werner. Jekyll makes it easy to create site-wide headers and footers without having to copy them across every page. It also offers intelligent blog support and other advanced templating features.\r\n\r\n### Authors and Contributors\r\nYou can @mention a GitHub username to generate a link to their profile. The resulting `<a>` element will link to the contributor's GitHub Profile. For example: In 2007, Chris Wanstrath (@defunkt), PJ Hyett (@pjhyett), and Tom Preston-Werner (@mojombo) founded GitHub.\r\n\r\n### Support or Contact\r\nHaving trouble with Pages? Check out the documentation at https://help.github.com/pages or contact support@github.com and we’ll help you sort it out.\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}