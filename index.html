<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Stager by arunesh-mittal</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Stager</h1>
      <h2 class="project-tagline">Image Registration and Analysis Interface</h2>
      <a href="https://github.com/arunesh-mittal/Stager" class="btn">View on GitHub</a>
      <a href="https://github.com/arunesh-mittal/Stager/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/arunesh-mittal/Stager/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h2>
<a id="image-registration-and-analysis-interface-stager" class="anchor" href="#image-registration-and-analysis-interface-stager" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image Registration and Analysis Interface ‘Stager’</h2>

<p><img src="https://raw.githubusercontent.com/arunesh-mittal/StagerWebpage/master/Screen%20Shot%202015-06-23%20at%208.01.52%20PM.png" alt=""></p>

<h3>
<a id="features" class="anchor" href="#features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Features:</h3>

<h4>
<a id="roi-selection" class="anchor" href="#roi-selection" aria-hidden="true"><span class="octicon octicon-link"></span></a>ROI Selection</h4>

<p>Allow the user to select an algorithm for ROI mask/map creation OR use a pre-computed ROI mask/map. In the future, support field-of-view search feature i.e. if the user selects a recorded volume, move scanner to find optimal alignment between pre-recorded volume and live acquisition.</p>

<h4>
<a id="image-registration" class="anchor" href="#image-registration" aria-hidden="true"><span class="octicon octicon-link"></span></a>Image Registration</h4>

<p>Given a reference volume perform allow user to choose a image registration algorithm (2D FFT cross correlation) and save the registered data either in the standard tiff format OR in a flat binary format (uint16) - one volume per file, one trials worth of files per directory with a standard naming of the files and directories. Add functionality to set the locations of these files to be on the cluster. In the future, other ways of sending the data to the network should be explored too. Performance Requirement: 8 Hz for 4 planes, 30 Hz for 1 plane.</p>

<p>Future work: Possibly allow user to specify or add registration algorithms. </p>

<h4>
<a id="roimap" class="anchor" href="#roimap" aria-hidden="true"><span class="octicon octicon-link"></span></a>ROI/Map</h4>

<p>ROIs can be given in two forms, either a binary ROI mask or a weighted Map. Given a set of ROIs (either binary or weighted) compute the inner product of each ROI with the current frame (either with or without motion registration). Performance Requirement: (8 Hz for 4 planes, 30 Hz for 1 plane)</p>

<h4>
<a id="time-series-display" class="anchor" href="#time-series-display" aria-hidden="true"><span class="octicon octicon-link"></span></a>Time-series display</h4>

<p>Following the inner product with the ROI, plot the time series. The GUI should allow users to specify which ROIs to plot. User should also be able to specify threshold for each ROI and trigger and event if an event is detected. </p>

<h4>
<a id="analog-outputdigital-output" class="anchor" href="#analog-outputdigital-output" aria-hidden="true"><span class="octicon octicon-link"></span></a>Analog Output/Digital Output</h4>

<p>The time series data should be scaled and output on AO channels from one of the NI boards (scaled ±10V or 0-5V). The user should be able so specify which ROIs to send to the Analog output. In addition, they should allow the setting of thresholds to do simple event detection and output pulses on DIO lines for detected events.</p>

<hr>

<h3>
<a id="implementation" class="anchor" href="#implementation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementation</h3>

<h4>
<a id="architecture" class="anchor" href="#architecture" aria-hidden="true"><span class="octicon octicon-link"></span></a>Architecture:</h4>

<p>Stager is based on a client/server architecture. Stager has a server which listens to clients and imports frames into Stager when the client marks the frame as ready. The client class must me initialized by any MATLAB routine which wants to send frames to the Stager. Stager itself is based on a object-oriented design - I believe this will allow for a lot of flexibility later with things like unit testing and modularity. </p>

<p>Stager currently has a routine that invokes SI5 to acquire n-Frames or uses a pre-acquired tif stack to generate a template image using Nick's pyramid scheme. As a new frame comes in, it is processed and added to the correct frameObject array within the appropriate timeSeriesObject by the Stager. The processing step currently includes the 2DFFT (x-correlation) registration. This takes~23ms+/-2ms - Note: this is on my windows virtual machine on a mac, I would expect the numbers to be much better on any SI rig machine based on FFT benchmarks I performed. </p>

<h4>
<a id="pipeline" class="anchor" href="#pipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Pipeline</h4>

<p>The stager runs in its own process i.e. scanImage and the analysis run as two separate processes (two different matlab sessions) - this allows for much better performance and avoids dropped frames on the SI5 process. Since, I have modeled the architecture as a server/client design, any service that wants to use the "Stager" must initialize an instance of the Stager client class. In the case of SI5, ScanImage starts a client session in a userfunction, the client maps each new incoming frame from the scanImage buffer into memory (memory mapped file) and sets a byte value - read flag. The stager server checks the flag and pulls the memory mapped frame, processes it and adds it to a timeSeries object as a frameObject. The client/server relationship between SI5 and Stager supports some low level communication, io flags, header info (channel, frameNum, zPlane) and also allows Stager to invoke some pre-defined SI functions. For example, to generate a new template image before starting acquisition, Stager can invoke the grab function in SI5 and acquire n-Frames to generate a new template image.This does not compromise The mapping of each frame and only takes ~1ms +/-3ms (again this is on my windows virtual machine on a mac). Here is a script that outlines some functionality - some of this will eventually be abstracted away in a GUI and higher level functions.</p>

<hr>

<h3>
<a id="commentsfeedback" class="anchor" href="#commentsfeedback" aria-hidden="true"><span class="octicon octicon-link"></span></a>Comments/Feedback</h3>

<h4>
<a id="comments" class="anchor" href="#comments" aria-hidden="true"><span class="octicon octicon-link"></span></a>Comments:</h4>

<p>NS: For each ROI might want to be able to set F0 value too and then toggle between looking at F and (F-F0)/F0. Thresholds and events will probably want to be defined in the (F-F0)/F0 domain.</p>

<p>It would be useful to flesh out in more detail exactly what the GUI will look like in the first instance (and how you might then want to expand it in the future). For example, how will you display or not display the static reference images, ROI mask / values. How will the user be able to set which ROIs to look at live and which ROIs to send to the AO, how will thresholds be set, how will F0 be set if we want to do an (F-F0)/F0 conversion.</p>

<p>It would also be useful to start laying out how you plan to do this under the hood – i.e. will this run in a separate matlab, what will happen if the registration takes too long (will it drop / skip frames, will the acquisition crash, will we be warned), what sort of timing guarantees will there be.</p>

<p>SP: you should add a neuropil capability; this will be important in many preparations.  It also introduces some problems -- the mask itself is easy, as it is an annulus that is between a range of distances away from the neuron border, but you have to exclude i) other selected ROIs and ii) pixels that are cells/big dendrites but are not part of an ROI.  ii) is tricky -- the way it is done now is that an image with peak correlation for each pixel to its 8 neighbors is computed, and any pixel where this exceeds (e.g.) 0.2 is excluded.  This is predicated on some activity being sampled, and its unclear how much activity is needed to establish this.  Its also quite processing intensive, and goes to Nick’s point about buffering data...</p>

<h4>
<a id="requested-features" class="anchor" href="#requested-features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Requested Features</h4>

<ul>
<li>asd</li>
<li><p>asd</p></li>
<li><p>1- Save the post-registered images online to a network location (for use for instance by Thunder)</p></li>
<li>2- Knobs to change contrast and colors in Stager with capability to overlay a currently acquired image and a saved one. </li>
<li>3- Running average of x frames (to smooth and to capture sparse neurons).</li>
<li>4- Robust and efficient calculation of F0 </li>
<li>5- A way to select from the ROI list which ROIs go to the NI output</li>
<li>6- A mode to downsample and reduce the refresh rate for the ROI activity display (to improve the latency)</li>
<li>7- User function that takes ROIs dF/F, extra parameters (weight matrix, etc) and sends the output to the NI </li>
<li><p>8- A cross-bar to indicate the X-Y and Z offsets with respect to the reference image.</p></li>
<li><p>Delta F/F should be user defined - plot histogram for each ROI and allow</p></li>
<li>user to pick threshold (example: 10% of values below threshold)</li>
<li>One template for both channels - allow user to pick the channel</li>
<li>Allow user to input external ROI (Use codeneuro data fromat)</li>
<li>Allow user to input external template (binary/JSON pair)</li>
<li>Trial info should be in the memfile header</li>
<li>Only keep track of last n frames</li>
<li>Explicit error message when frame is dropped</li>
<li>Fill dropped data with NaN/Zero</li>
<li>AO Daq - use NI DAQ board? Given 30Hz output might be overkill</li>
<li>For each time series data structure what happens when n-&gt;large N</li>
<li>Allow option for FFT on downsampled image for faster registration</li>
<li>Named Pipes/POSIX</li>
</ul>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/arunesh-mittal/Stager">Stager</a> is maintained by <a href="https://github.com/arunesh-mittal">arunesh-mittal</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>

